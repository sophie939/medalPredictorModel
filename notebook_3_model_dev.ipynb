{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olympic Medal Prediction - Model Development and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "Feature matrix shape: (21398, 16)\n",
      "Target shape: (21398,)\n",
      "Medal rate: 10.8%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    roc_curve, precision_recall_curve, accuracy_score, f1_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    X = pd.read_pickle('features_X.pkl')\n",
    "    y = pd.read_pickle('target_y.pkl')\n",
    "    with open('feature_names.pkl', 'rb') as f:\n",
    "        available_features = pickle.load(f)\n",
    "    \n",
    "    print(f\"Data loaded successfully:\")\n",
    "    print(f\"Feature matrix shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    print(f\"Medal rate: {y.mean():.1%}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Please run the EDA and feature engineering notebook first.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 17,118 samples\n",
      "Test set: 4,280 samples\n",
      "\n",
      "Training set target distribution:\n",
      "   No Medal: 89.2%\n",
      "   Medal: 10.8%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"\\nTraining set target distribution:\")\n",
    "train_dist = y_train.value_counts(normalise=True)\n",
    "print(f\"   No Medal: {train_dist[0]:.1%}\")\n",
    "print(f\"   Medal: {train_dist[1]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Gradient Boosting Model:\n",
      "CV AUC: 0.7506 (±0.0101)\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Gradient Boosting Model:\")\n",
    "\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gb', GradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3\n",
    "    ))\n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    baseline_pipeline, X_train, y_train, \n",
    "    cv=5, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "print(f\"CV AUC: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter Optimization:\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best CV Score: 0.7578\n",
      "Best Parameters: {'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__min_samples_split': 10, 'gb__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameter Optimisation:\")\n",
    "\n",
    "param_grid = {\n",
    "    'gb__n_estimators': [100, 200],\n",
    "    'gb__learning_rate': [0.05, 0.1, 0.15],\n",
    "    'gb__max_depth': [3, 4, 5],\n",
    "    'gb__min_samples_split': [10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    baseline_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST RESULTS:\n",
      "   AUC-ROC:  0.7646\n",
      "   Accuracy: 0.8963\n",
      "   F1-Score: 0.1591\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Medal       0.90      0.99      0.94      3818\n",
      "       Medal       0.64      0.09      0.16       462\n",
      "\n",
      "    accuracy                           0.90      4280\n",
      "   macro avg       0.77      0.54      0.55      4280\n",
      "weighted avg       0.87      0.90      0.86      4280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"FINAL TEST RESULTS:\")\n",
    "print(f\"   AUC-ROC:  {test_auc:.4f}\")\n",
    "print(f\"   Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Medal', 'Medal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most important features:\n",
      "=============================================\n",
      " 1. country_medal_rate       : 0.2557\n",
      " 2. sport_medal_rate         : 0.1088\n",
      " 3. fitness_score            : 0.0619\n",
      " 4. sport_avg_ranking        : 0.0573\n",
      " 5. bodyFat                  : 0.0572\n",
      " 6. bmi                      : 0.0542\n",
      " 7. vo2Max                   : 0.0520\n",
      " 8. risk_score               : 0.0513\n",
      " 9. bloodOxygen              : 0.0503\n",
      "10. heartRateVariability     : 0.0496\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': best_model['gb'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"10 most important features:\")\n",
    "print(\"=\" * 45)\n",
    "for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['feature']:<25}: {row['importance']:.4f}\")\n",
    "\n",
    "feature_categories = {\n",
    "    'Physical': ['height', 'weight', 'bmi'],\n",
    "    'Health': ['bodyFat', 'heartRateVariability', 'vo2Max', 'bloodOxygen', 'injurySeverityScore'],\n",
    "    'Derived': ['fitness_score', 'risk_score', 'estimated_age'],\n",
    "    'Economic': ['gdp_per_capita'],\n",
    "    'Performance': ['country_medal_rate', 'country_avg_ranking', 'sport_medal_rate', 'sport_avg_ranking']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = {\n",
    "    'model_name': 'Olympic Medal Predictor - Gradient Boosting',\n",
    "    'model_type': 'GradientBoostingClassifier',\n",
    "    'test_auc': test_auc,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_f1': test_f1,\n",
    "    'cv_score': grid_search.best_score_,\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'feature_names': available_features,\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "joblib.dump(best_model, 'olympic_medal_predictor_gb.pkl')\n",
    "joblib.dump(model_metadata, 'model_metadata.pkl')\n",
    "\n",
    "evaluation_results = {\n",
    "    'y_test': y_test,\n",
    "    'y_test_pred': y_test_pred,\n",
    "    'y_test_pred_proba': y_test_pred_proba,\n",
    "    'feature_importance_df': feature_importance_df,\n",
    "    'best_model': best_model,\n",
    "    'grid_search': grid_search\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as f:\n",
    "    pickle.dump(evaluation_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
